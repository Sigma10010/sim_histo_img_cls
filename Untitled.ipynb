{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from resnet import BasicBlock, Bottleneck\n",
    "net = Bottleneck(3, 5)\n",
    "y = net(torch.randn(1,3,32,32))\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 15000, 'T': 15000}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 10000, 'T': 9375}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       nan, 4.5677e-41, 1.2099e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.Tensor(1, 3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from datasets import BreakHis, BreakHisPIL\n",
    "import torch\n",
    "from networks import TripletClassificationNet, BreakHisEmbeddingNet\n",
    "from save_load import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptest = '/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/'\n",
    "test_dataset = BreakHisPIL(ptest,data_aug=False, transform=transforms.Compose([\n",
    "                                 transforms.ToTensor()\n",
    "\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/100X/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12312',\n",
       " '13412',\n",
       " '13413',\n",
       " '14134E',\n",
       " '15570C',\n",
       " '16188',\n",
       " '16196',\n",
       " '16601',\n",
       " '18650',\n",
       " '18842D',\n",
       " '190EF',\n",
       " '19440',\n",
       " '19854C',\n",
       " '19979',\n",
       " '21978AB',\n",
       " '22549CD',\n",
       " '22704',\n",
       " '23060AB',\n",
       " '23060CD',\n",
       " '2980',\n",
       " '2985',\n",
       " '29960CD',\n",
       " '3411F',\n",
       " '3909',\n",
       " '4364',\n",
       " '5287',\n",
       " '6241',\n",
       " '9461']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.slide_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(test_dataset.labels_set)\n",
    "cuda = torch.cuda.is_available()\n",
    "batch_size = 3\n",
    "kwargs = {'num_workers': 3, 'pin_memory': True} if cuda else {}\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 1\n",
    "embedding_net = BreakHisEmbeddingNet(n_classes)\n",
    "model = TripletClassificationNet(embedding_net, n_classes)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "ckpt_w = '/mnt/DATA_OTHER/breakHis/results/checkpoint/breakHis/ckpt_baseline_Triplet_C_breakHis1_daug_2l1**1.5beta_00011.t7'\n",
    "model=load_model_ckpt_w(model, ckpt_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/100X/SOB_B_TA-14-3411F-100-008.png', '/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/100X/SOB_M_DC-14-3909-100-026.png', '/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/100X/SOB_B_A-14-22549CD-100-001.png']\n"
     ]
    }
   ],
   "source": [
    "num_slide = len(dataloader.dataset.slide_name_list)\n",
    "ps_matrix = np.zeros((num_slide,2))\n",
    "for batch_idx, (data, target, slide_id, im_name) in enumerate(dataloader):\n",
    "    if batch_idx<1:\n",
    "        print(im_name)\n",
    "        break\n",
    "#     for i in slide_id.cpu().numpy():\n",
    "#         ps_matrix[i,1]+=1\n",
    "#     target = target if len(target) > 0 else None\n",
    "#     if not type(data) in (tuple, list):\n",
    "#         data = (data,)\n",
    "#     if cuda:\n",
    "#         data = tuple(d.cuda() for d in data)\n",
    "#         if target is not None:\n",
    "#             target = target.cuda()\n",
    "\n",
    "#     outputs = model.get_classification(*data)\n",
    "#     pred=outputs.max(1)[1]\n",
    "#     _slide_id = slide_id[pred==target]\n",
    "#     for j in _slide_id.cpu().numpy():\n",
    "#         ps_matrix[j,0]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.Tensor([1,1,0])\n",
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1b1cee8d9bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "im_name = torch.from_numpy(np.array(im_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/40X/SOB_M_PC-15-190EF-40-017.png',\n",
       " '/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/40X/SOB_M_PC-15-190EF-40-018.png']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[im_name[i] for i, value in enumerate(idx) if value==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (target==pred).cpu().numpy()\n",
    "for i in idx:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_id[target==pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-235b5917d7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "im_name[target==pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/DATA_OTHER/breakHis/mkfold/fold3/test/100X/SOB_B_TA-14-3411F-100-008.png'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.imglist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.885"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2577/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([149])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_slide_id.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False,  True,  True, False, False,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred!=target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
